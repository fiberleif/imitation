tasks:
  - name: hopper
    env: Hopper-v1
    policy: expert_policies/modern/log_Hopper-v0_3.h5/snapshots/iter0000500
    data_subsamp_freq: 1
    cuts_off_on_success: false
    out: log/hopper-v1

  - name: walker
    env: Walker2d-v1
    policy: expert_policies/modern/walker_eb5b2e_1.h5/snapshots/iter0000480
    data_subsamp_freq: 1
    cuts_off_on_success: false
    out: log/walker2d-v1

#  - name: ant
#    env: Ant-v1
#    policy: expert_policies/modern/log_Ant-v1_0.h5/snapshots/iter0000500
#    data_subsamp_freq: 20
#    cuts_off_on_success: false

  - name: halfcheetah
    env: HalfCheetah-v1
    policy: expert_policies/modern/log_HalfCheetah-v0_2.h5/snapshots/iter0000500
    data_subsamp_freq: 1
    cuts_off_on_success: false
    out: log/halfcheetah-v1

training:
  full_dataset_num_trajs: 50
  #dataset_num_trajs: [4, 11, 18, 25]
  dataset_num_trajs: [4]
  deterministic_expert: false
  runs: 1

  algorithms:
    # Generative adversarial imitation learning
    - name: ga
      cmd: >
        python scripts/imitate_mj.py --mode ga
        --env {env}
        --data {dataset}
        --limit_trajs {num_trajs}
        --data_subsamp_freq {data_subsamp_freq}
        --favor_zero_expert_reward {cuts_off_on_success}
        --min_total_sa 1000
        --max_iter 4000
        --reward_include_time 0
        --reward_lr .01
        --log {out}

options:
  storagedir: imitation_runs/modern_stochastic
  traj_subdir: trajs
  checkpt_subdir: checkpoints_all

  eval_num_trajs: 50
  results_filename: results.h5

  pbs:
    jobname: im_modern
    queue: atlas
    ppn: 12
